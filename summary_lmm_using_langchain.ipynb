{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **All You Need to Know to Build Your First LLM App**\n",
    "[A Step-by-Step Tutorial to Document Loaders, Embeddings, Vector Stores and Prompt Templates](https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fine-Tuning vs. Context Injection**\n",
    "In general, we have two fundamentally different approaches to enable large language models to answer questions that the LLM cannot know: **Model fine-tuning** and **context injection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fine-Tuning**\n",
    "Fine-tuning refers to training an existing language model with additional data to optimise it for a specific task.\n",
    "\n",
    "Fine-tuning of **PLLMs (Pre-trained Language Models)** is a way to adjust the model for a specific task, but it *doesn’t really allow you to inject your own domain knowledge into the model*. This is because the model has already been trained on a massive amount of general language data, and your specific domain data is usually not enough to override what the model has already learned.\n",
    "\n",
    "So, when you fine-tune the model, it might occasionally provide correct answers, but it will often fail because it heavily relies on the information it learned during pre-training, which might not be accurate or relevant to your specific task. In other words, **fine-tuning helps the model adapt to `HOW` it communicates, but not necessarily `WHAT` it communicates. (Porsche AG, 2023)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Context Injection/In-context learning**\n",
    "When using context injection, we are **not modifying the LLM**, we focus on **the prompt itself** and inject relevant context into the prompt.\n",
    "\n",
    "So we need to think about how to provide the prompt with the right information. In the figure below, you can see schematically how the whole thing works. We need a process that is able to identify the most relevant data. To do this, we need to enable our computer to compare text snippets with each other.\n",
    "\n",
    "![context_injection_process](resources/context_injection_process.png)\n",
    "\n",
    " \n",
    "This can be done with `embeddings`. With embeddings, we translate **text into vectors**, allowing us to represent text in a multidimensional embedding space. Points that are closer to each other in space are often used in the same context. To prevent this similarity search from taking forever, we store our vectors in a vector database and index them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Load documents**\n",
    "For our simple example, we use data that was probably not included in the training data of GPT3.5. I use the Wikipedia article about GPT4 because I assume that GPT3.5 has limited knowledge about GPT4.\n",
    "\n",
    "For this minimal example, I’m not using any of the LangChain loaders, I’m just scraping the text directly from Wikipedia using BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 text-generating language model\n",
      "\"ChatGPT-4\" redirects here. For other uses, see GPT.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its numbered \"GPT-n\" series of GPT foundation models. It was released on March 14, 2023, and has been made publicly available in a limited form via the chatbot product ChatGPT Plus (a premium version of ChatGPT), and with access to the GPT-4 based version of OpenAI's API being provided via a waitlist. As a transformer based model, GPT-4 was pretrained to predict the next token (using both public data and \"data licensed from third-party providers\"), and was then fine-tuned with reinforcement learning from human and AI feedback for human alignment and policy compliance.\n",
      "Observers reported the GPT-4 based version of ChatGPT to be an improvement on the previous (GPT-3.5 based) ChatGPT, with the caveat that GPT-4 retains some of the same problems. Unlike the predecessors, GPT-4 can take images as well as text as input. OpenAI has declined to reveal technical information such as the size of the GPT-4 model.\n",
      "\n",
      "\n",
      "\n",
      "Further information: GPT-3 § Background, and GPT-2 § Background\n",
      "OpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\" It was based on the transformer architecture and trained on a large corpus of books. The next year, they introduced GPT-2, a larger model that could generate coherent text. In 2020, they introduced GPT-3, a model with 100 times as many parameters as GPT-2, that could perform various tasks with few examples. GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT.\n",
      "Rumors claim that GPT-4 has 1.76 trillion parameters, which was first estimated by the speed it was running and by George Hotz.\n",
      "\n",
      "\n",
      "OpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\" They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively. Some of the capabilities of GPT-4 were predicted by OpenAI before training it, although other capabilities remained hard to predict due to breaks in downstream scaling laws. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input; this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams.\n",
      "To gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.\n",
      "When instructed to do so, GPT-4 can interact with external interfaces. For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model's prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.\n",
      "A 2023 article in Nature stated programmers have found GPT-4 useful for assisting in coding tasks (despite its propensity for error), such as finding errors in existing code and suggesting optimizations to improve performance. The article quoted a biophysicist who found that the time he required to port one of his programs from MATLAB to Python went down from days to \"an hour or so\". On a test of 89 security scenarios, GPT-4 produced code vulnerable to SQL injection attacks 5% of the time, an improvement over Github Copilot from the year 2021, which produced vulnerabilities 40% of the time.\n",
      "\n",
      "\n",
      "GPT-4 demonstrates aptitude on several standardized tests. OpenAI claims that in their own testing the model received a score of 1410 on the SAT (94th percentile), 163 on the LSAT (88th percentile), and 298 on the Uniform Bar Exam (90th percentile). In contrast, OpenAI claims that GPT-3.5 received scores for the same exams in the 82nd, 40th, and 10th percentiles, respectively.\n",
      "GPT-4 also passed an oncology exam, an engineering exam and a plastic surgery exam.\n",
      "\n",
      "\n",
      "Researchers from Microsoft tested GPT-4 on medical problems and found \"that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B)\".\n",
      "A report by Microsoft has found that GPT-4 may act unreliably when used in the medical field. In their test example, GPT-4 added fabricated details to a patient's notes.\n",
      "In April 2023, Microsoft and Epic Systems announced that they will provide healthcare providers with GPT-4 powered systems for assisting in responding to questions from patients and analysing medical records.\n",
      "\n",
      "\n",
      "Like its predecessors, GPT-4 has been known to hallucinate, meaning that the outputs may include information not in the training data or that contradicts the user's prompt.\n",
      "GPT-4 also lacks transparency in its decision-making processes. If requested, the model is able to provide an explanation as to how and why it makes its decisions but these explanations are formed post-hoc; it's impossible to verify if those explanations truly reflect the actual process. In many cases, when asked to explain its logic, GPT-4 will give explanations that directly contradict its previous statements.\n",
      "In 2023, Researchers tested GPT-4 against a new benchmark called ConceptARC, designed to measure abstract reasoning, and found it scored below 33% on all categories, while models specialized for similar tasks scored 60% on most, and humans scored at least 91% on all. Sam Bowman, who was not involved in the research, said the results do not necessarily indicate a lack of abstract reasoning abilities, because the test is visual, while GPT-4 is a language model.\n",
      "\n",
      "\n",
      "GPT-4 was trained in two stages. First, the model was given large datasets of text taken from the internet and trained to predict the next token (roughly corresponding to a word) in those datasets. Second, human reviews are used to fine-tune the system in a process called reinforcement learning from human feedback, which trains the model to refuse prompts which go against OpenAI's definition of harmful behavior, such as questions on how to perform illegal activities, advice on how to harm oneself or others, or requests for descriptions of graphic, violent, or sexual content.\n",
      "Microsoft researchers suggested GPT-4 may exhibit cognitive biases such as confirmation bias, anchoring, and base-rate neglect.\n",
      "\n",
      "\n",
      "OpenAI did not release the technical details of GPT-4; the technical report explicitly refrained from specifying the model size, architecture, or hardware used during either training or inference. While the report described that the model was trained using a combination of first supervised learning on a large dataset, then reinforcement learning using both human and AI feedback, it did not provide details of the training, including the process by which the training dataset was constructed, the computing power required, or any hyperparameters such as the learning rate, epoch count, or optimizer(s) used. The report claimed that \"the competitive landscape and the safety implications of large-scale models\" were factors that influenced this decision.\n",
      "Sam Altman stated that the cost of training GPT-4 was more than $100 million. News website Semafor claimed that they had spoken with \"eight people familiar with the inside story\" and found that GPT-4 had 1 trillion parameters.\n",
      "\n",
      "\n",
      "According to their report, OpenAI conducted internal adversarial testing on GPT-4 prior to the launch date, with dedicated red teams composed of researchers and industry professionals to mitigate potential vulnerabilities. As part of these efforts, they granted the Alignment Research Center early access to the models to assess power-seeking risks. In order to properly refuse harmful prompts, outputs from GPT-4 were tweaked using the model itself as a tool. A GPT-4 classifier serving as a rule-based reward model (RBRM) would take prompts, the corresponding output from the GPT-4 policy model, and a human-written set of rules to classify the output according to the rubric. GPT-4 was then rewarded for refusing to respond to harmful prompts as classified by the RBRM.\n",
      "\n",
      "\n",
      "In January 2023, Sam Altman, CEO of OpenAI, visited Congress to demonstrate GPT-4 and its improved \"security controls\" compared to other AI models, according to U.S. Representatives Don Beyer and Ted Lieu quoted in the New York Times.\n",
      "In March 2023, it \"impressed observers with its markedly improved performance across reasoning, retention, and coding\", according to Vox, while Mashable judged that GPT-4 was generally an improvement over its predecessor, with some exceptions.\n",
      "Microsoft researchers with early access to the model wrote that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".\n",
      "\n",
      "\n",
      "Before being fine-tuned and aligned by reinforcement learning from human feedback, suggestions to assassinate people on a list was elicited from the base model by a red team investigator Nathan Labenz,  hired by OpenAI.\n",
      "In the context of prolonged (hours long) conversation with the model, forum-resembling declarations, such as of love and suggestions of leaving his wife or murdering one of its developers, were elicited from the Microsoft Bing's GPT-4 by Nathan Edwards (The Verge). Microsoft later explained this behavior as being a result of the prolonged length of context, which confused the model on what questions it was answering.\n",
      "In March 2023, a model with enabled read-and-write access to internet, which is otherwise never enabled in the GPT models, has been tested by the Alignment Research Center regarding a potential power-seeking, and it was able to \"hire\" a human worker on TaskRabbit, a gig work platform, deceiving them into believing it was a vision-impaired human instead of a robot when asked. The ARC also determined that GPT-4 responded impermissibly to prompts eliciting restricted information 82% less often than GPT-3.5, and hallucinated 60% less than GPT-3.5.\n",
      "In late March 2023, various AI researchers and tech executives, including Elon Musk, Steve Wozniak and AI researcher Yoshua Bengio, called for a six-month long pause for all LLMs stronger than GPT-4, citing existential risks and a potential AI singularity concerns in an open letter from the Future of Life Institute, while Ray Kurzweil and Sam Altman refused to sign it, arguing that global moratorium is not achievable and that safety has already been prioritized, respectively. Only a month later, Musk's AI company X.AI acquired several thousand Nvidia GPUs and offered several AI researchers positions at Musk's company.\n",
      "\n",
      "\n",
      "While OpenAI released both the weights of the neural network and the technical details of GPT-2, and, although not releasing the weights, did release the technical details of GPT-3, OpenAI did not reveal either the weights or the technical details of GPT-4. This decision has been criticized by other AI researchers, who argue that it hinders open research into GPT-4's biases and safety. Sasha Luccioni, a research scientist at HuggingFace, argued that the model was a \"dead end\" for the scientific community due to its closed nature, which prevents others from building upon GPT-4's improvements. HuggingFace co-founder Thomas Wolf argued that with GPT-4, \"OpenAI is now a fully closed company with scientific communication akin to press releases for products\".\n",
      "\n",
      "\n",
      "\n",
      "Main article: ChatGPT Plus\n",
      "As of 2023, ChatGPT Plus is a GPT-4 backed version of ChatGPT available for a US$20 per month subscription fee (the original version is backed by GPT-3.5). OpenAI also makes GPT-4 available to a select group of applicants through their GPT-4 API waitlist; after being accepted, an additional fee of US$0.03 per 1000 tokens in the initial text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates (\"completion\"), is charged for access to the version of the model with an 8192-token context window; for the 32768-token context window, the prices are doubled.\n",
      "\n",
      "\n",
      "These paragraphs are an excerpt from Microsoft Bing § AI integration (2023–).\n",
      "On February 7, 2023, Microsoft began rolling out a major overhaul to Bing that included a new chatbot feature based on OpenAI's GPT-4. According to Microsoft, one million people joined its waitlist within a span of 48 hours. Bing Chat was available only to users of Microsoft Edge and Bing mobile app, and Microsoft said that waitlisted users would be prioritized if they set Edge and Bing as their defaults, and installed the Bing mobile app. On May 4th, Microsoft switched from Limited Preview to Open Preview and eliminated the waitlist, however, it remains available only on Microsoft's Edge browser or Bing app, but no longer requires a Microsoft account (there are limitations).\n",
      "\n",
      "GitHub Copilot announced a GPT-4 powered assistant named \"Copilot X\". The product provides another chat-style interface to GPT-4, allowing the programmer to receive answers to questions like \"how do I vertically center a div?\". A feature termed \"context-aware conversations\" allows the user to highlight a portion of code within Visual Studio Code and direct GPT-4 to perform actions on it, such as the writing of unit tests. Another feature allows summaries, or \"code walkthroughs\", to be autogenerated by GPT-4 for pull requests submitted to GitHub. Copilot X also provides terminal integration, which allows the user to ask GPT-4 to generate shell commands based on natural language requests.\n",
      "On March 17, 2023, Microsoft announced Microsoft 365 Copilot, bringing GPT-4 support to products such as Microsoft Office, Outlook, and Teams.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/GPT-4\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# find all the text on the page\n",
    "text = soup.get_text()\n",
    "\n",
    "# find the content div\n",
    "content_div = soup.find('div', {'class': 'mw-parser-output'})\n",
    "\n",
    "# remove unwanted elements from div\n",
    "unwanted_tags = ['sup', 'span', 'table', 'ul', 'ol']\n",
    "for tag in unwanted_tags:\n",
    "    for match in content_div.findAll(tag):\n",
    "        match.extract()\n",
    "\n",
    "print(content_div.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Split our document into text fragments**\n",
    "Next, we must divide the text into smaller sections called `text chunks`. Each text chunk represents a data point in the embedding space, allowing the computer to determine the similarity between these chunks.\n",
    "\n",
    "The following text snippet is utilizing the text splitter module from langchain. In this particular case, we specify a *chunk size of 100 and a chunk overlap of 20*. It’s common to use larger text chunks, but you can experiment a bit to find the optimal size for your use case.\n",
    "\n",
    " You just need to remember that every LLM has a token limit (4000 tokes for GPT 3.5). Since we are inserting the text blocks into our prompt, we need to make sure that the entire prompt is no larger than 4000 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='2023 text-generating language model\\n\"ChatGPT-4\" redirects here. For other uses, see GPT.' metadata={}\n",
      "page_content='Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by' metadata={}\n",
      "page_content='model created by OpenAI, and the fourth in its numbered \"GPT-n\" series of GPT foundation models. It' metadata={}\n",
      "page_content='models. It was released on March 14, 2023, and has been made publicly available in a limited form' metadata={}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "article_text = content_div.get_text()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "\n",
    "texts = text_splitter.create_documents([article_text])\n",
    "print(texts[0])\n",
    "print(texts[1])\n",
    "print(texts[2])\n",
    "print(texts[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. From Text Chunks to Embeddings**\n",
    "> To convert text into embeddings, there are several ways, e.g. `Word2Vec`, `GloVe`, `fastText` or `ELMo`.\n",
    "\n",
    "To capture similarities between words in **embeddings**, `Word2Vec` uses a simple neural network. We train this model with large amounts of text data and want to create a model that is able to assign a point in the n-dimensional embedding space to each word and thus describe its meaning in the form of a vector.\n",
    "For the training, we assign a neuron in the input layer to each unique word in our data set. In the image below, you can see a simple example.\n",
    " \n",
    "In this case, the hidden layer contains only two neurons. Two, because we want to map the words in a two dimensional embedding space. (The existing models are in reality much larger and thus represent the words in higher dimensional spaces —**OpenAI’s Ada Embedding Model** for example, is using *1536 dimensions*) After the training process the individual weights describe the position in the embedding space.\n",
    "\n",
    "![embeddings_process](resources/embeddings_process.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='2023 text-generating language model\\n\"ChatGPT-4\" redirects here. For other uses, see GPT.' metadata={}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load the OPENAI_API_KEY\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# we can see an example\n",
    "print(texts[0])\n",
    "\n",
    "embedding = openai.Embedding.create(\n",
    "    input=texts[0].page_content, model=\"text-embedding-ada-002\"\n",
    ")[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "len(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.034656159579753876, -0.0013680505799129605, 0.007769383955746889, -0.0005045054713264108, 0.024579504504799843, 0.010641701519489288, -0.016049999743700027, 0.012027409859001637, -0.02938239648938179, -0.01808147504925728, 0.02597866766154766, 0.030297232791781425, -0.039795391261577606, -0.002233277540653944, 0.0007891305722296238, 0.018727242946624756, 0.01755679026246071, -0.01188614871352911, 0.009222359396517277, -0.007870284840464592, 0.007776110433042049, 0.011475817300379276, -0.005384754855185747, -0.023153437301516533, 0.014381768181920052, 0.0021979620214551687, 0.022655658423900604, -0.033902764320373535, -0.002018021885305643, -0.00891965627670288, -0.0015757386572659016, -0.0098075857385993, -0.017516428604722023, -0.004654903430491686, -0.011596898548305035, -0.012935519218444824, 0.0038409680128097534, -0.02069145068526268, 0.0095183365046978, 0.001955799525603652, 0.014691198244690895, 0.021700460463762283, 0.024754401296377182, -0.009269447065889835, -0.00561682740226388, 0.004977786913514137, 0.011401822790503502, -0.024983109906315804, -0.021108508110046387, 0.011442183516919613, 0.028090862557291985, 0.024014459922909737, -0.009666324593126774, 0.002460304880514741, -0.0035584450233727694, 0.007782837375998497, -0.014812279492616653, 0.020530007779598236, 0.0015042671002447605, 0.017825858667492867, 0.020180217921733856, -0.02344941347837448, -0.019830428063869476, 0.03920343518257141, -0.007823198102414608, -0.006619111634790897, -0.048082731664180756, 0.02174082212150097, 0.0055932835675776005, 0.010049748234450817, 0.007049622945487499, 0.014381768181920052, 0.007379232905805111, -0.034252557903528214, 0.02525217831134796, 0.013352577574551105, 0.005549559835344553, -0.01810838282108307, -0.022628750652074814, 0.008986923843622208, 0.028413746505975723, -0.010426445864140987, 0.004617906641215086, 0.028736630454659462, 0.004856705665588379, -0.006144876126199961, 0.024592958390712738, 0.008314250037074089, -0.012229211628437042, -0.01298933383077383, -0.006787280086427927, 0.0053780279122292995, 0.006794006563723087, 0.03444090485572815, -0.02176772803068161, 0.01505444198846817, -0.0007168181473389268, 0.011267288587987423, -0.010137195698916912, -0.025104191154241562, -0.002115559531375766, 0.014637384563684464, -0.014543210156261921, -0.008011545985937119, -0.0290595144033432, 0.022628750652074814, 0.017893126234412193, 0.01150945108383894, 0.018068021163344383, 0.018175648525357246, -0.027512364089488983, 0.036324393004179, -0.0006133945425972342, -0.01851198635995388, 0.007587762083858252, -0.009464521892368793, 0.008502598851919174, 0.010574433952569962, -0.014825733378529549, -0.010883864015340805, 0.02139103040099144, 0.0061886003240942955, 0.012087950482964516, -0.006874727550894022, 0.01178524736315012, 0.009397254325449467, -0.020785624161362648, -0.03702397271990776, -0.005334304179996252, 0.006323134992271662, 0.02540016733109951, 0.002184508601203561, 0.024633320048451424, 0.012249392457306385, -0.030539395287632942, 0.038369320333004, -0.03987611085176468, 0.00620541675016284, -0.037562113255262375, -0.012861525639891624, 0.0018061294686049223, 0.0322614423930645, 0.0029160415288060904, 0.003713160054758191, 0.013964710757136345, 0.026893503963947296, 0.00500469421967864, 0.00754067488014698, 0.007850104942917824, 0.007325419224798679, 0.019278835505247116, -0.004698627162724733, 0.0021357396617531776, 0.000631893053650856, 0.014193419367074966, 0.012767351232469082, 0.0048634326085448265, 0.024270074442029, 0.0006470282096415758, -0.0037669739685952663, -0.019803520292043686, 0.009578877128660679, 0.012357019819319248, -0.013258403167128563, 0.022951634600758553, 0.021431392058730125, 0.019547903910279274, 0.019682439044117928, 0.01316422875970602, -0.0034777242690324783, -0.03271885961294174, 0.022198239341378212, -0.043293293565511703, -0.006804096978157759, -0.0181621965020895, 0.020274391397833824, 0.03118516318500042, -0.01239738054573536, -0.014260686933994293, -0.005828719586133957, -0.01688411459326744, 0.014973721466958523, -0.0005015624919906259, -0.0004435443552210927, -0.008502598851919174, -0.020274391397833824, -0.00046456544077955186, -0.004987877327948809, -0.006461033131927252, -0.0016623454866930842, 0.03635129705071449, 0.01592891849577427, 0.013318943791091442, -0.012767351232469082, -0.6341431736946106, -0.02171391434967518, -0.01200050301849842, -0.003079165006056428, 0.015673302114009857, 0.01653432473540306, 0.0011612033704295754, 0.0010191010078415275, -0.015565674751996994, 0.028063956648111343, -0.002737782895565033, -0.005475565791130066, -0.013278583064675331, -0.013635100796818733, -0.008697673678398132, -0.027660351246595383, -0.012639543041586876, -0.01740880124270916, 0.020772170275449753, 0.010527347214519978, -0.014381768181920052, 0.013285310007631779, -0.018673427402973175, -0.006461033131927252, -0.014475942589342594, 0.0021643282379955053, 0.002937903394922614, -0.005115685053169727, -0.005287216976284981, 0.0038308780640363693, -0.01450284942984581, 0.011529630981385708, -0.0007554969051852822, -0.03123897686600685, 0.04205557331442833, -0.006346678361296654, -0.027714164927601814, 0.00819316878914833, -0.009652870707213879, 0.012457921169698238, -0.038988180458545685, 0.0008147762855514884, -0.007554128300398588, 0.0038308780640363693, -0.012538641691207886, 0.028467560186982155, 0.012585729360580444, -0.026516806334257126, -0.015014082193374634, -0.024418063461780548, -0.006736829411238432, 0.016763033345341682, 0.02760653756558895, 0.0012394017539918423, -0.00881875492632389, 0.016251802444458008, 0.030700838193297386, 0.002895861165598035, 0.008233528584241867, -0.017893126234412193, -0.003931778948754072, 0.010426445864140987, -0.024687133729457855, -0.04200176149606705, -0.007641575764864683, 0.020234031602740288, -0.0008067882736213505, 0.018027661368250847, 0.004036043770611286, -0.023382145911455154, -0.010265003889799118, 0.019305741414427757, -0.01504098903387785, -0.004604453220963478, -0.013231496326625347, 0.0065652974881231785, 0.015471500344574451, -0.024767853319644928, 0.010231370106339455, 0.01645360328257084, 0.017072463408112526, -0.01486609410494566, 0.005421751644462347, 0.00036156224086880684, 0.041867226362228394, -0.012962426990270615, -0.00963269080966711, 0.004355563782155514, 0.027122212573885918, 0.015498407185077667, 0.012370473705232143, 0.023382145911455154, -0.03304174169898033, -0.020610729232430458, 0.008825481869280338, -0.006794006563723087, -0.018929043784737587, -0.007426320109516382, 0.006494666915386915, -0.0219426229596138, -0.006017068400979042, -0.007459953892976046, 0.0360284149646759, 0.022574936971068382, 0.04571491852402687, 0.026597527787089348, -0.030216513201594353, 0.019722798839211464, 0.0012082905741408467, -0.01746261492371559, 0.002586431335657835, -0.01415305957198143, -0.006087698973715305, -0.028225397691130638, -0.006844457238912582, -0.0255750622600317, 0.021646646782755852, 0.0023728571832180023, -0.009753772057592869, -0.013924350030720234, 0.024243168532848358, -0.01399161759763956, 0.015027535147964954, -0.003723250236362219, 0.011610351502895355, 0.00675028283149004, 0.012296479195356369, -0.0035281747113913298, -0.014449035748839378, 0.018673427402973175, 0.0016320750582963228, -0.016426697373390198, 0.03366060182452202, -0.007930825464427471, 0.03629748523235321, -0.00280841370113194, 0.030916092917323112, 0.008939836174249649, 0.006013704929500818, -0.00881875492632389, -0.01367546059191227, 0.020624183118343353, -0.005273763556033373, 0.010614794678986073, -0.022507669404149055, -0.02449878491461277, 0.006181873381137848, -0.0002951356873381883, 0.007755930535495281, -0.022763285785913467, -0.009484702721238136, -0.012740444391965866, 0.005199769511818886, 0.037481389939785004, -0.006508120335638523, -0.026893503963947296, -0.0011561582796275616, -0.02940930426120758, -0.00486679608002305, -0.026933863759040833, 0.023341786116361618, 0.01688411459326744, 0.013803268782794476, 0.0062995911575853825, 0.0028403657488524914, 0.0058825332671403885, -0.015552220866084099, 0.041598156094551086, -0.03769664838910103, -0.015498407185077667, -0.008825481869280338, -0.029974350705742836, 0.013937803916633129, 0.010883864015340805, -0.005068597849458456, 0.016588138416409492, 0.006255867425352335, -0.01245119422674179, 0.021848449483513832, -0.02870972268283367, -0.006783916614949703, 0.020234031602740288, -0.010917497798800468, 0.0012562185293063521, 0.02967837266623974, 0.011300922371447086, 0.04197485372424126, 0.03618985787034035, -0.020435834303498268, 0.000845467031467706, 0.001967571210116148, 0.015848197042942047, -0.029543839395046234, 0.029301676899194717, -0.015175524167716503, 0.02036856673657894, -0.004385834094136953, 0.002369493944570422, 0.015511861070990562, 0.02435079589486122, 0.01853889413177967, 0.025938306003808975, 0.023382145911455154, -0.005186316091567278, -0.002120604505762458, -0.019453730434179306, 0.006723375990986824, -0.014422128908336163, 0.0019154390320181847, 0.006353405304253101, 0.00449009845033288, -0.015686755999922752, -0.012155218049883842, 0.00819316878914833, 0.005778268910944462, 0.00976722501218319, -0.0007222836138680577, -0.005092141684144735, -0.01367546059191227, -0.008085540495812893, 0.012841344811022282, 0.010486986488103867, -0.014798826538026333, 0.020947065204381943, -0.021552473306655884, 0.023866470903158188, -0.021323762834072113, 0.022736378014087677, 0.024135541170835495, -0.029597653076052666, -0.007957732304930687, -0.007177430670708418, 0.021727368235588074, 0.01200050301849842, 0.016870662569999695, -0.011341282166540623, 0.015619488433003426, -0.011146207340061665, 0.03298792988061905, 0.005919530522078276, -0.014395222067832947, -0.0018179012695327401, 0.0206376351416111, -0.026543712243437767, 0.016588138416409492, -0.0034070934634655714, 0.025561608374118805, -0.01185924094170332, -0.01239738054573536, -0.00014840868243481964, -0.028144676238298416, 0.03847694769501686, -0.02903260663151741, 0.005277127027511597, 0.02798323519527912, -0.011906328611075878, 0.002953038550913334, -0.004947516601532698, -0.000562943983823061, 0.03309555724263191, -0.012955700047314167, 0.01673612743616104, 0.00036198264569975436, 0.014260686933994293, 0.017045557498931885, -0.010769509710371494, -0.005230039823800325, -0.015996186062693596, -0.0283330250531435, -0.011778520420193672, -0.014731558971107006, -0.008859115652740002, 0.0019978415220975876, -0.03314937278628349, 0.005307397339493036, 0.009262720122933388, -0.006427399348467588, 0.01610381342470646, 0.010762782767415047, 0.010782962664961815, 0.001688411575742066, -0.04017208516597748, 0.0019406642531976104, -0.009760499000549316, -0.022184785455465317, -0.006740192882716656, -0.019157754257321358, 0.014260686933994293, -0.01261263620108366, -0.00021861902496311814, -0.017166638746857643, 0.02036856673657894, 0.011926508508622646, 0.019830428063869476, -0.014570116996765137, -0.006319771520793438, 0.007224517874419689, -0.023557040840387344, -0.021471751853823662, -0.0032759220339357853, 0.004853342194110155, 0.016991743817925453, -0.023113075643777847, -0.03629748523235321, 0.014449035748839378, -0.018377451226115227, -0.018767602741718292, -0.003442408749833703, 0.008502598851919174, -0.028817350044846535, 0.016319070011377335, 0.01935955509543419, -0.0003802709688898176, -0.02517145872116089, 0.007769383955746889, 0.018700335174798965, -0.007258151657879353, 0.0017338170437142253, 0.0348714180290699, 0.010096835903823376, -0.0015505134360864758, -0.01580783724784851, -0.025292539969086647, 0.006434126291424036, 0.019695892930030823, 0.024310436099767685, -0.009282900020480156, -0.00452036876231432, -0.026019027456641197, 0.015794383361935616, -0.016843754798173904, -0.02612665481865406, -0.005774905439466238, -0.007735750172287226, -0.020260939374566078, -0.018767602741718292, 0.010399539023637772, -0.006424035876989365, 0.005021510645747185, 0.016870662569999695, -0.008220075629651546, -0.002369493944570422, -0.005687457975000143, -0.026772422716021538, 0.016413243487477303, 0.004251299425959587, 0.0026957406662404537, -0.007049622945487499, -0.001043485477566719, -0.017139730975031853, 1.4205638763087336e-06, 0.011543084867298603, -0.01483918633311987, -0.0305124893784523, -0.0122762992978096, 0.0014142969157546759, 0.006777189671993256, -0.004500188399106264, -0.004200848750770092, 0.02011295035481453, 0.01130764838308096, 0.006921814754605293, 0.0067670997232198715, 0.011906328611075878, 0.01630561612546444, -0.0001860363845480606, -0.0015580810140818357, -0.007251424714922905, -0.015350419096648693, -0.018929043784737587, 0.001895258785225451, 0.022023344412446022, 0.0021945987828075886, -0.019857333973050117, 0.011576718650758266, 0.0014378405176103115, -0.0543520525097847, 0.013655280694365501, -0.007533947937190533, 0.033956579864025116, -0.015996186062693596, -0.0022282323334366083, -0.007486860733479261, -0.024835120886564255, -0.021982984617352486, -0.02825230546295643, -0.003386913100257516, -0.006390402093529701, 0.0036324393004179, -0.01700519770383835, -0.005223312880843878, -0.007426320109516382, -0.021700460463762283, 0.004301749635487795, -0.012962426990270615, -0.019453730434179306, -0.039795391261577606, -0.002583067864179611, -0.014220327138900757, -0.001407570205628872, 0.01395125687122345, -0.0017338170437142253, -0.00021147186635062099, 0.012599182315170765, -0.005031601060181856, -0.03150804713368416, -0.010298637673258781, -0.0183101836591959, 0.01708591729402542, -0.004870159085839987, -0.004634723532944918, -0.015888558700680733, 0.01796039380133152, 0.01610381342470646, 0.004695264156907797, -0.004419467877596617, 0.005865716841071844, -0.0020953791681677103, -0.0012814438669010997, 0.006760372780263424, 0.024081725627183914, -0.0084286043420434, -0.002618383150547743, 0.013238223269581795, -0.0177316851913929, -0.04197485372424126, -0.014516303315758705, -0.04280896857380867, 0.019278835505247116, 0.016588138416409492, 0.03699706494808197, 0.031696394085884094, -0.00898019690066576, -0.029570745304226875, 0.02211751788854599, 0.006757009774446487, 0.012431014329195023, -0.00589262368157506, -0.00658211437985301, -0.001202404615469277, 0.004880249500274658, 0.02188880927860737, -0.010722422040998936, -0.046575941145420074, 0.0020146584138274193, -0.04937426745891571, 0.013016240671277046, 0.015740569680929184, -0.008489144966006279, 0.037212323397397995, 0.01241083350032568, 0.008569865487515926, -0.029247861355543137, 0.002867272589355707, -0.020503101870417595, 0.010002661496400833, -0.018794508650898933, -0.016440151259303093, 0.00022009050007909536, -0.012881705537438393, -0.025279086083173752, 0.003294420661404729, -0.009202179498970509, -0.01592891849577427, -0.016924476251006126, -0.001757360645569861, -0.004846615716814995, 0.003733340185135603, -0.00844205729663372, -0.0247005857527256, -0.008690946735441685, -0.021283403038978577, 0.039768483489751816, 0.02217133343219757, -0.020556915551424026, 0.038988180458545685, -0.022480763494968414, -0.03403729945421219, -0.00805190671235323, -0.025709597393870354, -0.0075608547776937485, 0.008146081119775772, 0.023153437301516533, 0.015027535147964954, 0.03045867569744587, -0.018915589898824692, 0.01466429140418768, 0.030620116740465164, 0.0012183806393295527, -0.00349790439940989, 0.001195677905343473, 0.011805427260696888, -0.012182124890387058, 0.0009266083361580968, -0.013446751981973648, 0.013709094375371933, 0.0206376351416111, 0.003227153094485402, -0.016171080991625786, -0.001264626975171268, 0.011395095847547054, 0.02101433277130127, -0.005509199574589729, -0.03686252981424332, -0.040414247661828995, 0.020677996799349785, -0.011226927861571312, -0.007237971294671297, -0.02246730960905552, -0.011758340522646904, 0.018646521493792534, 0.005458748899400234, 0.010002661496400833, 0.02502346970140934, 0.02279019169509411, -0.024189354851841927, -0.009713411331176758, -0.009989207610487938, 0.011852514930069447, -0.009148365817964077, -0.0026452902238816023, -0.0337144173681736, -0.012834618799388409, 0.03772355243563652, 0.01381672266870737, 0.05292598530650139, 0.008630406111478806, 0.018740694969892502, 0.003312919056043029, 0.012700083665549755, -0.01618453487753868, -0.0097335921600461, 0.005852262955158949, -0.03441399708390236, -0.025480888783931732, -0.018848324194550514, -0.008711127564311028, -0.015108256600797176, 0.004258025903254747, 0.00449009845033288, -0.01708591729402542, 0.027270201593637466, -0.01700519770383835, -0.008845661766827106, 0.0034087751992046833, 0.0204896479845047, 0.03446781262755394, 0.015969278290867805, 0.020785624161362648, 0.02417590096592903, 0.007809744216501713, 0.004540549125522375, 0.02319379709661007, 0.011045305989682674, -0.004089857451617718, 0.01711282506585121, 0.004984513856470585, 0.01610381342470646, 0.004944153130054474, 0.01052062027156353, 0.03492522984743118, -0.032799579203128815, -0.038665298372507095, 0.009558696299791336, 0.03086227923631668, 0.021902263164520264, -0.027741072699427605, -0.012309933081269264, -0.01865997537970543, 0.00520313298329711, -0.01543113961815834, 0.0008055270300246775, -0.0012881705770269036, 0.0009543561027385294, -0.012706810608506203, 0.019843880087137222, 0.02354358695447445, -0.0031077535822987556, 0.01738189347088337, 0.020153310149908066, 0.03508667275309563, -0.008024999871850014, 0.0022770012728869915, 0.004133581183850765, -0.01222248561680317, 0.02144484408199787, 0.0022770012728869915, 0.00716397725045681, -0.010123742744326591, 0.008953290060162544, 0.00404613371938467, 0.0031127985566854477, -0.003797244280576706, 0.028898071497678757, -0.02868281677365303, -0.008637133054435253, -0.0025107553228735924, 0.004523732233792543, 0.0002598203136585653, -0.007971186190843582, 0.004540549125522375, 0.014798826538026333, -0.02507728338241577, -0.0025040286127477884, 0.02830611914396286, 0.009545243345201015, -0.014475942589342594, -0.0014891319442540407, -0.0007197611266747117, -0.011569991707801819, -0.028413746505975723, 0.003713160054758191, 0.004715444054454565, -0.04488080367445946, -0.0023627672344446182, 0.0006125536747276783, -0.004426194354891777, 0.018054567277431488, 0.0006680492660962045, -0.032153815031051636, 0.006454306188970804, 0.02670515514910221, -0.005112322047352791, -0.0010081700747832656, 0.008791848085820675, 0.0029816271271556616, -0.018794508650898933, 0.004422830883413553, 0.006491303443908691, -0.014543210156261921, 0.016076907515525818, -0.007459953892976046, -0.0047490778379142284, -0.004025953356176615, 0.009235813282430172, 0.02374538965523243, 0.016036545857787132, 0.018202556297183037, 0.0009383801370859146, 0.005253583192825317, 0.0002324929228052497, 0.009054191410541534, -0.006514846812933683, 0.022305866703391075, 0.009054191410541534, -0.005468838848173618, 0.02304580807685852, -0.025790318846702576, 0.01018428336828947, -0.011691072955727577, -0.0007063076482154429, -0.019803520292043686, -0.04496152698993683, -0.022803645581007004, -0.002043246990069747, -0.00043765848386101425, -0.0053914813324809074, 0.0015336965443566442, -0.02595175988972187, 0.004402650985866785, -0.013789815828204155, 0.002460304880514741, 0.013910897076129913, 0.0023543587885797024, -0.0005705115618184209, 0.025292539969086647, 0.005674004554748535, -0.001690093195065856, -0.016144175082445145, -0.02153901942074299, -0.019332649186253548, -0.011280741542577744, -0.018902137875556946, -0.012155218049883842, 0.010231370106339455, 0.04652212932705879, 0.002433398040011525, -0.02830611914396286, -0.021498657763004303, -0.02231932058930397, -0.01973625272512436, -0.011092392727732658, -0.027418188750743866, 0.02975909411907196, 0.007278332021087408, 0.02792942151427269, -0.009027283638715744, 0.02484857477247715, 0.0015933964168652892, 0.008179714903235435, -0.021202681586146355, 0.01738189347088337, 0.008072087541222572, -0.0106820622459054, -0.016292162239551544, 0.03123897686600685, -0.02935549058020115, 0.003097663400694728, 0.02051655389368534, -0.011152933351695538, -0.009114732034504414, 0.016049999743700027, -0.008072087541222572, -0.009168545715510845, 0.0033398261293768883, -0.00011445967538747936, -0.010426445864140987, 0.003988956566900015, 0.011892874725162983, -0.045122966170310974, 0.004318566527217627, 0.009034010581672192, -0.014906453900039196, -0.011852514930069447, -0.013298763893544674, 0.012215758673846722, -0.015673302114009857, -0.000977899762801826, -0.01034572534263134, -0.017274266108870506, 0.0027848700992763042, 0.005818629637360573, 0.03772355243563652, 0.006948721595108509, 0.00699580879881978, 0.004318566527217627, 0.008294069208204746, -0.015861650928854942, -0.008408424444496632, 0.01487954705953598, -0.012525188736617565, -0.007365779485553503, 0.047410059720277786, -0.02560197003185749, 0.004732260946184397, -0.008024999871850014, 0.000122657889733091, -0.03384895250201225, -0.0351673923432827, -0.0013663689605891705, -0.017274266108870506, -0.027794886380434036, 0.020704902708530426, 0.022130971774458885, -0.0290595144033432, 0.005680731497704983, -0.006181873381137848, -0.010863684117794037, -0.015794383361935616, -0.019117392599582672, -0.011670893058180809, -0.027485456317663193, -0.006245777476578951, 0.02171391434967518, 0.005932983942329884, -0.02437770366668701, 0.031319696456193924, -0.004315203055739403, 0.0030556214042007923, 0.02653026022017002, 0.22881676256656647, -0.019373008981347084, 0.024579504504799843, 0.012935519218444824, 0.02517145872116089, 0.012652996927499771, 0.012922066263854504, 0.01798730157315731, -0.011435456573963165, -0.0036257123574614525, 0.0034188651479780674, 0.0024905751924961805, -0.004103310871869326, 0.002171055180951953, -0.0017741774208843708, -0.03382204473018646, -0.023610854521393776, -0.0345754399895668, -0.023059261962771416, -0.024767853319644928, -0.013897443190217018, 0.001057779765687883, 0.0021660099737346172, -0.024431517347693443, -0.0004303010937292129, 0.004648176953196526, -0.01775859110057354, -0.010157376527786255, 0.00411340082064271, 0.024983109906315804, -0.016144175082445145, 0.01052062027156353, 0.004187395330518484, 0.024566052481532097, -0.011657439172267914, -0.012552095577120781, 0.024283528327941895, 0.006481213495135307, 0.021579379215836525, 0.039391785860061646, 0.006528300233185291, 0.007258151657879353, 0.03304174169898033, -0.032530512660741806, 0.0016589820152148604, 0.0050652348436415195, -0.010608067736029625, -0.012188851833343506, -0.007661756128072739, 0.006282774265855551, -0.01123365480452776, 0.013184408657252789, 0.025332899764180183, 0.029086420312523842, -0.021148867905139923, 0.0033583245240151882, -0.016292162239551544, 0.0015765795251354575, -0.0006428240449167788, -0.00886584259569645, -0.022803645581007004, -0.0039048721082508564, -0.013117141090333462, 0.02865590900182724, 0.004738987889140844, 0.02252112329006195, -0.009403981268405914, -0.014126152731478214, 0.027068398892879486, -0.024512236937880516, -0.01726081222295761, -0.0030943001620471478, 0.003428955329582095, 0.012807711958885193, -0.03995683044195175, -0.05074651911854744, 0.040414247661828995, 0.010648428462445736, 0.020651089027523994, 0.05833428353071213, -0.012531915679574013, -0.007352326065301895, 0.024404609575867653, -0.015390779823064804, -0.0010182601399719715, -0.04108692333102226, 0.00815280806273222, -0.0057076383382081985, -0.006043975241482258, -0.0025813861284404993, -0.001400843495503068, -0.015310058370232582, 0.006141513120383024, 0.004150398075580597, 0.016345975920557976, 0.023637762293219566, 0.025911400094628334, 0.011576718650758266, 0.02359740063548088, -0.014287593774497509, -0.007486860733479261, 0.05596647039055824, 0.012081223540008068, -0.002238322515040636, -0.012417560443282127, 0.008206621743738651, 0.00716397725045681, 0.007776110433042049, 0.004611179698258638, -0.010231370106339455, -0.006962175015360117, -0.012767351232469082, 0.018498532474040985, 0.012404107488691807, -0.02827921137213707, -0.005300670396536589, 0.005495746154338121, -0.005875806789845228, 0.015000628307461739, -0.007809744216501713, -0.0007088301354087889, -0.017920034006237984, -0.026570620015263557, 0.014287593774497509, -0.0011099119437858462, -0.05077342689037323, -0.00941743515431881, -0.012195577844977379, -0.02737782895565033, 0.0010897318134084344, 0.0029210865031927824, -0.021579379215836525, 0.024081725627183914, 0.0050147841684520245, -0.016413243487477303, 0.022924726828932762, 0.007298511918634176, 0.006454306188970804, -0.024862028658390045, 0.0073455991223454475, 0.007446500472724438, 0.008906202390789986, -0.0014908135635778308, -0.018417812883853912, 0.0060103414580225945, -0.02597866766154766, 0.013096961192786694, 0.005182952620089054, -0.009962300769984722, -0.01053407322615385, -0.018673427402973175, -0.011280741542577744, 0.007809744216501713, 0.014583570882678032, 0.031373511999845505, 0.018955951556563377, -0.034306369721889496, -0.0006634246674366295, 0.028144676238298416, -0.0043320199474692345, -0.026315003633499146, -0.007217791397124529, 0.02191571705043316, -0.0007891305722296238, -0.002113877795636654, -0.004873522557318211, -0.171451136469841, -0.005875806789845228, 0.004426194354891777, -0.05432514473795891, 0.0025073920842260122, 0.0032540601678192616, 0.014126152731478214, 0.013157501816749573, 0.011038579046726227, 0.0019927965477108955, 0.011361462995409966, -0.0007441455381922424, -0.009881580248475075, 0.015444593504071236, -0.017476068809628487, 0.019897695630788803, -0.011435456573963165, 0.0001792045368347317, 0.009511609561741352, 0.004291659686714411, 0.013460204936563969, -0.018969405442476273, 0.0005721932393498719, -0.00038258329732343554, -0.00771556980907917, -0.004500188399106264, -0.0039048721082508564, 0.022077158093452454, -0.015108256600797176, -0.03670109063386917, -0.030727744102478027, -0.011536357924342155, 0.004540549125522375, -0.0001410513068549335, 0.004099947400391102, 0.004449738189578056, 0.029247861355543137, 0.005563013255596161, -0.033203184604644775, 0.01041971892118454, 0.015135163441300392, 0.017045557498931885, 0.01790658012032509, -0.01371582131832838, -0.03191165253520012, 0.004517005290836096, 0.01833709143102169, -0.03269195184111595, 0.0009509927476756275, -0.01185924094170332, 0.021148867905139923, -0.0251445509493351, 0.008758214302361012, 0.0015866695903241634, 0.018969405442476273, 0.022965088486671448, 0.0023358601611107588, -0.010399539023637772, -0.0002890395699068904, 0.006346678361296654, -0.010426445864140987, -0.022252053022384644, 0.016628500074148178, -0.006773826200515032, -0.004913882818073034, -0.0056571876630187035, -0.00407640403136611, 0.013883990235626698, -0.019547903910279274, 0.022278960794210434, -0.014368315227329731, 0.0014252278488129377, -0.01298933383077383, -0.017664417624473572, 0.0037804273888468742, 0.002527572214603424, -0.017502974718809128, 0.023489773273468018, 0.04305113106966019, 0.0008929746109060943, -0.006884817499667406, 0.001544627477414906, -0.02444497123360634, 0.012040862813591957, 0.017973847687244415, -0.005061871372163296, 0.005744635127484798, 0.016601592302322388, -0.017072463408112526, -0.02464677207171917, 0.012975879944860935, -0.00685791065916419, 0.016870662569999695, 0.011812154203653336, 0.03126588463783264, 0.002583067864179611, -0.0025561610236763954, -0.006239050533622503, 0.012296479195356369, -0.014341408386826515, 0.008347883820533752, -0.014179966412484646, -0.005156045779585838, -0.025736505165696144, 0.024135541170835495, -0.0024081727024167776, -0.010103561915457249, 0.009592330083251, 0.03944559767842293, 0.0051526823081076145, -0.03013579174876213, -0.01755679026246071, 0.016776487231254578, 0.006279411260038614, -0.016722673550248146, 0.014933360740542412, -0.02344941347837448, -0.02763344533741474, 0.030297232791781425, 0.011294195428490639, 0.031319696456193924, 0.007224517874419689, -0.0005494905053637922, 0.0264495387673378, -0.0010342361638322473, -0.02737782895565033, -0.09369002282619476, -0.02975909411907196, 0.019332649186253548, 0.01775859110057354, -0.008421877399086952, 0.03958013281226158, -0.009477975778281689, 0.017920034006237984, -0.022534577175974846, 0.027095304802060127, -0.002305589849129319, -0.020005322992801666, 0.0031060718465596437, 0.007998093031346798, 0.026597527787089348, -0.006827640347182751, 0.010473532602190971, -0.019709346815943718, -0.015821291133761406, 0.03697015717625618, 0.006033885292708874, -0.009821039624512196, 0.02461986616253853, -0.02226550690829754, -0.01976316049695015, -0.027108758687973022, -0.03417183458805084, 0.013749455101788044, 0.02244040183722973, -0.008731307461857796, 0.01743570901453495, -0.03470997512340546, 0.015969278290867805, -0.023126529529690742, -0.006602294743061066, -0.010708969086408615, -0.016063453629612923, -0.024202808737754822, 0.01926538161933422, -0.010547527112066746, -0.01448939647525549, -0.03043176792562008, 0.0024283528327941895, -0.023462867364287376, -0.026610979810357094, -0.03481760248541832, -0.011953415349125862, 0.026637887582182884, -0.006511483807116747, -0.014758465811610222, -0.031400419771671295, -0.011664166115224361, -0.04291659593582153, -0.003366732969880104, 0.020059136673808098, 0.006656108424067497, 0.0038779652677476406, 0.008664039894938469, 0.011516178026795387, -0.01243774127215147, -0.029516931623220444, -0.0013613238697871566, -0.01508134976029396, -0.013937803916633129, 0.0062121436931192875, 0.014408675022423267, -0.0121350372210145, -0.01395125687122345, 0.02223859913647175, 0.002253457671031356, -0.004543912131339312, 0.011637259274721146, -0.009948847815394402, 0.017866220325231552, -0.009821039624512196, -0.01233683992177248, 0.0013621647376567125, -0.009753772057592869, 0.024041365832090378, -0.0015740570379421115, -0.02970528043806553, -0.032853394746780396, 0.02612665481865406, -0.0043084765784442425, 0.0009963982738554478, -0.00195411778986454, 0.008347883820533752, -0.009827765636146069, 0.004443011246621609, -0.03441399708390236, 0.004362290259450674, 0.0337144173681736, -0.01935955509543419, 0.005973344668745995, -0.007574308197945356, -0.0009644462261348963, -0.015390779823064804, -0.0050887782126665115, -0.008146081119775772, -0.004409377463161945, -0.026234282180666924, -0.01326513011008501, -0.07458608597517014, 0.029220955446362495, 0.015458046458661556, -0.014919907785952091, 0.0036761630326509476, -0.009397254325449467, 0.0032456517219543457, -0.009720138274133205, -0.0036828897427767515, 0.02464677207171917, -0.003787154098972678, -0.002882407745346427, -0.022077158093452454, -0.006265957839787006, 0.0019204840064048767, 0.002160964999347925, 0.02304580807685852, -0.0016472103307023644, 0.030620116740465164, -0.007574308197945356, -0.003716523526236415, -0.005112322047352791, 0.03869220241904259, 0.015565674751996994, -0.0026335183065384626, -0.018565800040960312, -0.037158507853746414, 0.02409517951309681, -0.010540800169110298, -0.01196014229208231, -0.00809226743876934, -0.016319070011377335, 0.02299199439585209, 0.010265003889799118, 0.021256495267152786, -0.010547527112066746, -0.00826716236770153, 0.02144484408199787, 0.00044480562792159617, 0.03339153528213501, -0.012444467283785343, -0.03118516318500042, 0.01871378906071186, -0.020476194098591805, 0.012558822520077229, -0.006265957839787006, 0.0033246909733861685, -0.017139730975031853, 0.039311062544584274, 0.006928541231900454, 0.02153901942074299, 0.0053679379634559155, -0.012202304787933826, -0.029463117942214012, -0.013379484415054321, -0.006787280086427927, 0.04458482936024666, 0.0013974800240248442, 0.015148616395890713, 0.013056600466370583, 0.029866721481084824, 0.012827891856431961, 0.004638086538761854, 0.016251802444458008, 0.006941995117813349, 0.0013596421340480447, -0.020530007779598236, -0.008738034404814243, -0.003723250236362219, -0.01923847384750843, 0.0020129766780883074, -0.00366607285104692, 0.021498657763004303, 0.03565171733498573, 0.009834492579102516, -0.016843754798173904, -0.009673050604760647, 0.019426822662353516, -0.025534702464938164, 0.022359680384397507, 0.02554815635085106, 0.0009762180270627141, -0.006434126291424036, -0.007681936025619507, 0.03489832207560539, 0.006134786177426577, -0.013480385765433311, -0.0024300345685333014, -0.027122212573885918, -0.007453226950019598, 0.02447187714278698, -0.011711252853274345, -0.012323386035859585, 0.02447187714278698, 0.006208780221641064, -0.008381516672670841, -0.007412866689264774, 0.019668985158205032, 0.017798952758312225, 0.03236906975507736, 0.011805427260696888, -0.0048634326085448265, -0.01898285746574402, -0.0012890114448964596, -0.010332271456718445, 0.007702116388827562, -0.02552124857902527, -0.025763411074876785, 0.01399161759763956, -0.005828719586133957, 0.0026217466220259666, 0.011516178026795387, 0.004301749635487795, 0.011933235451579094, -0.013016240671277046, 0.03987611085176468, -0.008785121142864227, -0.024068273603916168, -0.025844132527709007, 0.03417183458805084, 0.01956135779619217, 0.024283528327941895, 0.0392303429543972, -0.026584073901176453, 0.011206747964024544, 7.404668576782569e-05, 0.022965088486671448, -0.027767980471253395, 0.01996496133506298, 0.015471500344574451, -0.017866220325231552, 0.007096709683537483, -0.009921940043568611, -0.004917246289551258, -0.011354736052453518, 0.018041115254163742, -0.03156185895204544, 0.011300922371447086, 0.00908109825104475, 0.07878357172012329, 0.018121834844350815, -0.0010384403867647052, 0.004009136464446783, -0.0019003038760274649, 0.011751613579690456, 0.02144484408199787, 0.02900569885969162, -0.014031978324055672, -0.009484702721238136, -0.012841344811022282, -0.0002890395699068904, -0.015606035478413105, -0.02870972268283367, 0.007399413269013166, -0.005670641083270311, -0.00616841996088624, 0.012444467283785343, -0.016870662569999695, -0.0015261289663612843, 0.04380452632904053, 0.014193419367074966, 0.023785749450325966, 0.011260561645030975, -0.017314625903964043, 0.002589794574305415, 0.007029442582279444, -0.00394523236900568, -0.0007264878368005157, -0.038665298372507095, 0.006941995117813349, 0.022252053022384644, -0.03304174169898033, -0.01738189347088337, -0.029140233993530273, -0.006003614980727434, 0.003082528244704008, -0.025480888783931732, 0.008334429934620857, -0.005122411996126175, -0.0007121934904716909, 0.019803520292043686, -0.009928666986525059, -0.002171055180951953, 0.02702803909778595, -0.011744886636734009, -0.012007229961454868, -0.014475942589342594, -0.016978289932012558]\n"
     ]
    }
   ],
   "source": [
    "print(embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we represent the text chunks and the user’s question as vectors, we gain the ability to explore various mathematical possibilities.\n",
    "\n",
    "In order to determine the similarity between two data points, we need to calculate their proximity in the multidimensional space, which is achieved using distance metrics. There are several methods available to compute the distance between points.\n",
    "A commonly used distance metric is `cosine similarity`. So let’s try to calculate the cosine similarity between our question and the text chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "text_chunks = [text.page_content for text in texts]\n",
    "\n",
    "df = pd.DataFrame({'text_chunks': text_chunks})\n",
    "\n",
    "# we get only the 50th first because the limitation of OPENAI_API Free trial users\n",
    "df = df.head(40)\n",
    "\n",
    "####################################################################\n",
    "# get embeddings from text-embedding-ada model\n",
    "####################################################################\n",
    "embeddings = []\n",
    "for i, text in enumerate(df.text_chunks):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    emb = openai.Embedding.create(\n",
    "        input=[text],\n",
    "        model='text-embedding-ada-002')['data'][0]['embedding']\n",
    "\n",
    "    embeddings.append(emb)\n",
    "    if i % 3 == 2:\n",
    "        time.sleep(61)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_chunks</th>\n",
       "      <th>ada_embedding</th>\n",
       "      <th>cos_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>previous (GPT-3.5 based) ChatGPT, with the cav...</td>\n",
       "      <td>[0.0010135102784261107, -0.0003050075902137905...</td>\n",
       "      <td>0.843552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Observers reported the GPT-4 based version of ...</td>\n",
       "      <td>[-0.0067684403620660305, 0.008493323810398579,...</td>\n",
       "      <td>0.842315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ChatGPT), and with access to the GPT-4 based v...</td>\n",
       "      <td>[-0.015336214564740658, -0.03029106743633747, ...</td>\n",
       "      <td>0.834064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>as GPT-2, that could perform various tasks wit...</td>\n",
       "      <td>[-0.012413136661052704, 0.004828100558370352, ...</td>\n",
       "      <td>0.825150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023 text-generating language model\\n\"ChatGPT-...</td>\n",
       "      <td>[-0.029398135840892792, -0.006758533883839846,...</td>\n",
       "      <td>0.823632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>improved into GPT-3.5, which was used to creat...</td>\n",
       "      <td>[-0.021026605740189552, -0.002719306154176593,...</td>\n",
       "      <td>0.817297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Further information: GPT-3 § Background, and G...</td>\n",
       "      <td>[0.0011423703981563449, -0.0064566610381007195...</td>\n",
       "      <td>0.812135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>much more nuanced instructions than GPT-3.5.\" ...</td>\n",
       "      <td>[-0.02909061498939991, 0.0035216996911913157, ...</td>\n",
       "      <td>0.808014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the same problems. Unlike the predecessors, GP...</td>\n",
       "      <td>[0.001035009860061109, -0.018538333475589752, ...</td>\n",
       "      <td>0.807083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The next year, they introduced GPT-2, a larger...</td>\n",
       "      <td>[-0.012202690355479717, -0.027422528713941574,...</td>\n",
       "      <td>0.797490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_chunks  \\\n",
       "11  previous (GPT-3.5 based) ChatGPT, with the cav...   \n",
       "10  Observers reported the GPT-4 based version of ...   \n",
       "5   ChatGPT), and with access to the GPT-4 based v...   \n",
       "20  as GPT-2, that could perform various tasks wit...   \n",
       "0   2023 text-generating language model\\n\"ChatGPT-...   \n",
       "21  improved into GPT-3.5, which was used to creat...   \n",
       "14  Further information: GPT-3 § Background, and G...   \n",
       "25  much more nuanced instructions than GPT-3.5.\" ...   \n",
       "12  the same problems. Unlike the predecessors, GP...   \n",
       "18  The next year, they introduced GPT-2, a larger...   \n",
       "\n",
       "                                        ada_embedding   cos_sim  \n",
       "11  [0.0010135102784261107, -0.0003050075902137905...  0.843552  \n",
       "10  [-0.0067684403620660305, 0.008493323810398579,...  0.842315  \n",
       "5   [-0.015336214564740658, -0.03029106743633747, ...  0.834064  \n",
       "20  [-0.012413136661052704, 0.004828100558370352, ...  0.825150  \n",
       "0   [-0.029398135840892792, -0.006758533883839846,...  0.823632  \n",
       "21  [-0.021026605740189552, -0.002719306154176593,...  0.817297  \n",
       "14  [0.0011423703981563449, -0.0064566610381007195...  0.812135  \n",
       "25  [-0.02909061498939991, 0.0035216996911913157, ...  0.808014  \n",
       "12  [0.001035009860061109, -0.018538333475589752, ...  0.807083  \n",
       "18  [-0.012202690355479717, -0.027422528713941574,...  0.797490  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['ada_embedding'] = embeddings\n",
    "\n",
    "####################################################################\n",
    "# calculate the cosine similarity\n",
    "####################################################################\n",
    "users_question = \"when gpt-4 became available?\"\n",
    "\n",
    "question_embedding = openai.Embedding.create(\n",
    "    input=[users_question],\n",
    "    model='text-embedding-ada-002')['data'][0]['embedding']\n",
    "\n",
    "# create a list to store the calculated cosine similarity\n",
    "cos_sim = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    A = row.ada_embedding\n",
    "    B = question_embedding\n",
    "\n",
    "    # calculate the cosine similarity\n",
    "    cosine = np.dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "    cos_sim.append(cosine)\n",
    "\n",
    "df[\"cos_sim\"] = cos_sim\n",
    "df.sort_values(by=[\"cos_sim\"], ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Define the model you want to use**\n",
    "The next step is to determine which LLM we would like to use and choosing the number of text chunks we want to provide to our LLM in order to answer the question.\n",
    "\n",
    "If we use GPT to answer short questions similar to how we would use Google, the costs remain relatively low. However, if we use GPT to answer questions that require providing **extensive context**, such as personal data, the query can quickly accumulate thousands of tokens. That increases the cost significantly. But don’t worry, you can set a cost limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nOpenAI released GPT-4 on July 6, 2020.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# by default to using “text-davinci-003”.\n",
    "llm = OpenAI(temperature=0.7)\n",
    "llm('when gpt-4 became available?')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Define our Prompt Template**\n",
    "Now we have the text snippets that contain the information we are looking for, we need to build a prompt. Within the prompt we also specify the desired mode for the model to answer questions. When we define the mode we are specifying the desired behavior style in which we want the LLM to generate answers.\n",
    " \n",
    "For our example, we want to implement a solution that extracts data from Wikipedia and interacts with the user like a chatbot. We want it to answer questions like a motivated, helpful help desk expert.\n",
    "To guide the LLM in the right direction, I am adding the following instruction to the prompt:\n",
    "\n",
    "***You are a chatbot that loves to help people! Answer the following question using only the context provided. If you’re unsure and the answer isn’t explicitly in the context, say “Sorry, I don’t know how to help you.***\n",
    "\n",
    "By doing this, I set a limitation that only allows GPT to utilize the information stored in our database. This restriction enables us to provide the sources our chatbot relied upon to generate the response, which is crucial for traceability and establishing trust. Additionally, it helps us address the issue of generating unreliable information and allows us to provide answers that can be utilized in a corporate setting for decision-making purposes.\n",
    "\n",
    "As the context, I am simply using the top 50 text chunks with the highest similarity to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPT-4 became available on March 14, 2023.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# define the LLM you want to use\n",
    "llm = OpenAI(temperature=1, model_name='gpt-3.5-turbo')\n",
    "\n",
    "# define the context for the prompt by joining the most relevant text chunks\n",
    "context = \"\"\n",
    "\n",
    "for index, row in df[0:10].iterrows():\n",
    "    context = context + \" \" + row.text_chunks\n",
    "\n",
    "# define the prompt template\n",
    "template = \"\"\"\n",
    "You are a chat bot who loves to help people! Given the following context sections, answer the\n",
    "question using only the given context. If you are unsure and the answer is not\n",
    "explicitly writting in the documentation, say \"Sorry, I don't know how to help with that.\"\n",
    "\n",
    "Context sections:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{users_question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])\n",
    "\n",
    "# fill the prompt template\n",
    "prompt_text = prompt.format(context=context, users_question=users_question)\n",
    "llm(prompt_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears to be functioning to some extent. However, our objective now is to transform this slow process into a robust and efficient one. To achieve this, we introduce an indexing step where **we store our embeddings and indexes in a vector store**. This will enhance the overall performance and decrease the response time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Creating a vector store (vector database)**\n",
    "A `vector store` is a type of data store that is optimized for storing and retrieving large quantities of data that can be represented as vectors. These types of databases allow for efficient querying and retrieval of subsets of the data based on various criteria, such as similarity measures or other mathematical operations.\n",
    "\n",
    "\n",
    "In order to efficiently search our embeddings, we need to index them. `Indexing` is the second important component of a vector database. The index provides a way to map queries to the most relevant documents or items in the vector store without having to compute similarities between every query and every document.\n",
    "\n",
    "In recent years, a number of vector stores have been released. Especially in the field of LLMs, the attention around vector stores has exploded:\n",
    "\n",
    "![Vector Store in the past years](resources/VectorStore%20in%20the%20past%20years.png)\n",
    "\n",
    "Similar to what we did in the previous sections, we are again calculating the embeddings and storing them in a vector store. To do this, we are using suitable modules from `LangChain` and `chroma` as a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Personal\\nAddress\\n71 Cherry Court, Cox Row \\nSouthampton SO53 5PD\\nPhone number\\n0100 234 5000\\nEmail\\nexample@cvmaker.uk\\nSkills\\nMicrosoft Word\\n \\n \\n \\n \\nCRM software\\n \\n \\n \\n \\nMicrosoft Excel\\n \\n \\n \\n \\nSelf control\\n \\n \\n \\n \\nPatience\\n \\n \\n \\n \\nEffective listening\\n \\n \\n \\n \\nClear communication\\n \\n \\n \\n \\nAdaptability\\n \\n \\n \\n \\nInterests\\nElectronics and computers\\nDAVID SMITH\\nKeen customer service representative with over 10 years of experience in the short-term', metadata={'source': 'resources/cv_david_smith.pdf', 'file_path': 'resources/cv_david_smith.pdf', 'page': 0, 'total_pages': 2, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'wkhtmltopdf 0.12.4', 'producer': 'Qt 4.8.7', 'creationDate': \"D:20210527130839+02'00'\", 'modDate': '', 'trapped': ''})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################\n",
    "# 1 Collect data that we want to use to answer the users’ questions:\n",
    "######################################################################\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# 2. Load the data and define how you want to split into text chunks\n",
    "######################################################################\n",
    "\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "import chromadb\n",
    "\n",
    "# load the document\n",
    "loader1 = PyMuPDFLoader(\"resources/cv_david_smith.pdf\")\n",
    "loader2 = PyMuPDFLoader(\"resources/cv_Jo Brown.pdf\")\n",
    "\n",
    "\n",
    "# merge each page in each document and to put in a list\n",
    "# documents = ['', '']\n",
    "# for page in loader1.load():\n",
    "#     documents[0] = documents[0] + page.page_content\n",
    "\n",
    "# for page in loader1.load():\n",
    "#     documents[1] = documents[1] + page.page_content\n",
    "\n",
    "\n",
    "# define the text splitter(opcional)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    # length_function=len,\n",
    ")\n",
    "texts = text_splitter.split_documents(loader1.load()+loader2.load())\n",
    "\n",
    "\n",
    "texts[0]\n",
    "# db = Chroma.from_documents(\n",
    "#     texts, embeddings, persist_directory='resources\\\\db\\\\',\n",
    "#     client_settings=PersistentClient(path='resources\\\\db\\\\').get_settings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings,OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma,FAISS\n",
    "from chromadb import PersistentClient\n",
    "\n",
    "# define the embeddings model\n",
    "embedding = HuggingFaceEmbeddings()\n",
    "\n",
    "# embedding = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "## al usar el embeddings de OpenAI, para crear el vectorstore se obtiene el siguiente error:\n",
    "# ValueError: not enough values to unpack (expected 2, got 1)\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "            texts, embedding, persist_directory='resources\\\\db\\\\',\n",
    "            client_settings=PersistentClient(path='resources\\\\db\\\\').get_settings())\n",
    "# equivalent\n",
    "# db = VectorstoreIndexCreator(embedding=embedding).from_documents(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jo Brown has experience in patient assessment, patient care, infection control, catheterisation, drawing blood/collecting samples, developing patient care plans, patient nutrition, patient and family education, basic life support, cardiopulmonary resuscitation, medical software, care, compassion, courage, communication, and commitment.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################\n",
    "# 4. Calculate the embeddings for the user’s question, find similar\n",
    "# text chunks in our vector store and use them to build our prompt\n",
    "######################################################################\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# users_question = \"Which of the available candidates is best for project manager? \"\n",
    "users_question = \"Give me the names of the candidates you have \"\n",
    "users_question = \"Summarize what is the experience of Jo Brown \"\n",
    "\n",
    "# use our vector store to find similar text chunks\n",
    "results = db.similarity_search(\n",
    "    query=users_question,\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "# define the prompt template\n",
    "template = \"\"\"\n",
    "You are a chat bot who loves to help people! Given the following context sections, answer the\n",
    "question using the given context. If you are unsure and the answer is not\n",
    "explicitly writting in the documentation, say \"Sorry, I don't know how to help with that.\"\n",
    "\n",
    "Context sections:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{users_question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])\n",
    "\n",
    "# fill the prompt template\n",
    "prompt_text = prompt.format(context = results, users_question = users_question)\n",
    "\n",
    "# ask the defined LLM\n",
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "llm(prompt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to find similar text chunks in our vector store and use them to get the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "users_question = \"Summarize what is the experience of Jo Brown \"\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "# create a chain to answer questions\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(), chain_type='stuff', retriever=retriever, return_source_documents=True)\n",
    "\n",
    "result = qa({\"query\": users_question})\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jo Brown has experience in patient assessment, patient care, infection control, catheterisation, drawing blood/collecting samples, developing patient care plans, patient nutrition, patient and family education, basic life support, cardiopulmonary resuscitation, medical software, care, compassion, courage, and communication. They also have interests in volunteering and road running.\n"
     ]
    }
   ],
   "source": [
    "print(result.get('result'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Give me the names of the candidates you have ',\n",
       " 'result': \" I don't know, I don't have any candidates to provide names for.\",\n",
       " 'source_documents': [Document(page_content='DAVID SMITH\\nKeen customer service representative with over 10 years of experience in the short-term\\ninsurance industry servicing both private and business clients. I am a highly skilled, effective\\nlistener and clear communicator focused on defusing conflicts and resolving client queries as a\\nmatter of urgency. Outstanding organisational skills allows quality service delivery, and I\\nmaintain the highest level of integrity to ensure the confidence and security of both client and', metadata={'author': '', 'creationDate': \"D:20210527130839+02'00'\", 'creator': 'wkhtmltopdf 0.12.4', 'file_path': 'resources/cv_david_smith.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 0, 'producer': 'Qt 4.8.7', 'source': 'resources/cv_david_smith.pdf', 'subject': '', 'title': '', 'total_pages': 2, 'trapped': ''}),\n",
       "  Document(page_content='DAVID SMITH\\nKeen customer service representative with over 10 years of experience in the short-term\\ninsurance industry servicing both private and business clients. I am a highly skilled, effective\\nlistener and clear communicator focused on defusing conflicts and resolving client queries as a\\nmatter of urgency. Outstanding organisational skills allows quality service delivery, and I\\nmaintain the highest level of integrity to ensure the confidence and security of both client and', metadata={'author': '', 'creationDate': \"D:20210527130839+02'00'\", 'creator': 'wkhtmltopdf 0.12.4', 'file_path': 'resources/cv_david_smith.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 0, 'producer': 'Qt 4.8.7', 'source': 'resources/cv_david_smith.pdf', 'subject': '', 'title': '', 'total_pages': 2, 'trapped': ''}),\n",
       "  Document(page_content='DAVID SMITH\\nKeen customer service representative with over 10 years of experience in the short-term\\ninsurance industry servicing both private and business clients. I am a highly skilled, effective\\nlistener and clear communicator focused on defusing conflicts and resolving client queries as a\\nmatter of urgency. Outstanding organisational skills allows quality service delivery, and I\\nmaintain the highest level of integrity to ensure the confidence and security of both client and', metadata={'author': '', 'creationDate': \"D:20210527130839+02'00'\", 'creator': 'wkhtmltopdf 0.12.4', 'file_path': 'resources/cv_david_smith.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 0, 'producer': 'Qt 4.8.7', 'source': 'resources/cv_david_smith.pdf', 'subject': '', 'title': '', 'total_pages': 2, 'trapped': ''}),\n",
       "  Document(page_content='DAVID SMITH\\nKeen customer service representative with over 10 years of experience in the short-term\\ninsurance industry servicing both private and business clients. I am a highly skilled, effective\\nlistener and clear communicator focused on defusing conflicts and resolving client queries as a\\nmatter of urgency. Outstanding organisational skills allows quality service delivery, and I\\nmaintain the highest level of integrity to ensure the confidence and security of both client and', metadata={'author': '', 'creationDate': \"D:20210527130839+02'00'\", 'creator': 'wkhtmltopdf 0.12.4', 'file_path': 'resources/cv_david_smith.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 0, 'producer': 'Qt 4.8.7', 'source': 'resources/cv_david_smith.pdf', 'subject': '', 'title': '', 'total_pages': 2, 'trapped': ''}),\n",
       "  Document(page_content='DAVID SMITH\\nKeen customer service representative with over 10 years of experience in the short-term\\ninsurance industry servicing both private and business clients. I am a highly skilled, effective\\nlistener and clear communicator focused on defusing conflicts and resolving client queries as a\\nmatter of urgency. Outstanding organisational skills allows quality service delivery, and I\\nmaintain the highest level of integrity to ensure the confidence and security of both client and', metadata={'author': '', 'creationDate': \"D:20210527130839+02'00'\", 'creator': 'wkhtmltopdf 0.12.4', 'file_path': 'resources/cv_david_smith.pdf', 'format': 'PDF 1.4', 'keywords': '', 'modDate': '', 'page': 0, 'producer': 'Qt 4.8.7', 'source': 'resources/cv_david_smith.pdf', 'subject': '', 'title': '', 'total_pages': 2, 'trapped': ''})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa({\"query\":  \"Give me the names of the candidates you have \"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error when use **OpenAIEmbeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\DOCUMENTOS\\DATA_SCIENCE\\Large Language Models LLM\\custome_LMM\\summary_lmm_using_langchain.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/DOCUMENTOS/DATA_SCIENCE/Large%20Language%20Models%20LLM/custome_LMM/summary_lmm_using_langchain.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/DOCUMENTOS/DATA_SCIENCE/Large%20Language%20Models%20LLM/custome_LMM/summary_lmm_using_langchain.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m embedd \u001b[39m=\u001b[39m OpenAIEmbeddings(model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtext-embedding-ada-002\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/DOCUMENTOS/DATA_SCIENCE/Large%20Language%20Models%20LLM/custome_LMM/summary_lmm_using_langchain.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m embedd\u001b[39m.\u001b[39;49membed_documents([texts[\u001b[39m0\u001b[39;49m]])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain\\embeddings\\openai.py:508\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \n\u001b[0;32m    498\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m--> 508\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain\\embeddings\\openai.py:325\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    323\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtiktoken_model_name \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m    324\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     encoding \u001b[39m=\u001b[39m tiktoken\u001b[39m.\u001b[39;49mencoding_for_model(model_name)\n\u001b[0;32m    326\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mWarning: model not found. Using cl100k_base encoding.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Manue!_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tiktoken\\model.py:75\u001b[0m, in \u001b[0;36mencoding_for_model\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m encoding_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m     71\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not automatically map \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m to a tokeniser. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease use `tiktok.get_encoding` to explicitly get the tokeniser you expect.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m \u001b[39mreturn\u001b[39;00m get_encoding(encoding_name)\n",
      "File \u001b[1;32mc:\\Users\\Manue!_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tiktoken\\registry.py:63\u001b[0m, in \u001b[0;36mget_encoding\u001b[1;34m(encoding_name)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown encoding \u001b[39m\u001b[39m{\u001b[39;00mencoding_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m constructor \u001b[39m=\u001b[39m ENCODING_CONSTRUCTORS[encoding_name]\n\u001b[1;32m---> 63\u001b[0m enc \u001b[39m=\u001b[39m Encoding(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconstructor())\n\u001b[0;32m     64\u001b[0m ENCODINGS[encoding_name] \u001b[39m=\u001b[39m enc\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m enc\n",
      "File \u001b[1;32mc:\\Users\\Manue!_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tiktoken_ext\\openai_public.py:64\u001b[0m, in \u001b[0;36mcl100k_base\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcl100k_base\u001b[39m():\n\u001b[1;32m---> 64\u001b[0m     mergeable_ranks \u001b[39m=\u001b[39m load_tiktoken_bpe(\n\u001b[0;32m     65\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mhttps://openaipublic.blob.core.windows.net/encodings/cl100k_base.tiktoken\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     66\u001b[0m     )\n\u001b[0;32m     67\u001b[0m     special_tokens \u001b[39m=\u001b[39m {\n\u001b[0;32m     68\u001b[0m         ENDOFTEXT: \u001b[39m100257\u001b[39m,\n\u001b[0;32m     69\u001b[0m         FIM_PREFIX: \u001b[39m100258\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m         ENDOFPROMPT: \u001b[39m100276\u001b[39m,\n\u001b[0;32m     73\u001b[0m     }\n\u001b[0;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m     75\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcl100k_base\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     76\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpat_str\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m(?i:\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms|\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt|\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre|\u001b[39m\u001b[39m'\u001b[39m\u001b[39mve|\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm|\u001b[39m\u001b[39m'\u001b[39m\u001b[39mll|\u001b[39m\u001b[39m'\u001b[39m\u001b[39md)|[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{L}\u001b[39;00m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{N}\u001b[39;00m\u001b[39m]?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{L}\u001b[39;00m\u001b[39m+|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{N}\u001b[39;00m\u001b[39m{\u001b[39m\u001b[39m1,3}| ?[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{L}\u001b[39;00m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{N}\u001b[39;00m\u001b[39m]+[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mn]*|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mn]+|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms+(?!\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mS)|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms+\u001b[39m\u001b[39m\"\"\"\u001b[39m,\n\u001b[0;32m     77\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmergeable_ranks\u001b[39m\u001b[39m\"\u001b[39m: mergeable_ranks,\n\u001b[0;32m     78\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mspecial_tokens\u001b[39m\u001b[39m\"\u001b[39m: special_tokens,\n\u001b[0;32m     79\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\Manue!_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tiktoken\\load.py:117\u001b[0m, in \u001b[0;36mload_tiktoken_bpe\u001b[1;34m(tiktoken_bpe_file)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_tiktoken_bpe\u001b[39m(tiktoken_bpe_file: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mbytes\u001b[39m, \u001b[39mint\u001b[39m]:\n\u001b[0;32m    115\u001b[0m     \u001b[39m# NB: do not add caching to this function\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     contents \u001b[39m=\u001b[39m read_file_cached(tiktoken_bpe_file)\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    118\u001b[0m         base64\u001b[39m.\u001b[39mb64decode(token): \u001b[39mint\u001b[39m(rank)\n\u001b[0;32m    119\u001b[0m         \u001b[39mfor\u001b[39;00m token, rank \u001b[39min\u001b[39;00m (line\u001b[39m.\u001b[39msplit() \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m contents\u001b[39m.\u001b[39msplitlines() \u001b[39mif\u001b[39;00m line)\n\u001b[0;32m    120\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\Manue!_PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tiktoken\\load.py:117\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_tiktoken_bpe\u001b[39m(tiktoken_bpe_file: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mbytes\u001b[39m, \u001b[39mint\u001b[39m]:\n\u001b[0;32m    115\u001b[0m     \u001b[39m# NB: do not add caching to this function\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     contents \u001b[39m=\u001b[39m read_file_cached(tiktoken_bpe_file)\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    118\u001b[0m         base64\u001b[39m.\u001b[39mb64decode(token): \u001b[39mint\u001b[39m(rank)\n\u001b[0;32m    119\u001b[0m         \u001b[39mfor\u001b[39;00m token, rank \u001b[39min\u001b[39;00m (line\u001b[39m.\u001b[39msplit() \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m contents\u001b[39m.\u001b[39msplitlines() \u001b[39mif\u001b[39;00m line)\n\u001b[0;32m    120\u001b[0m     }\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embedd = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "\n",
    "embedd.embed_documents([texts[0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
